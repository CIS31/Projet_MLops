from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse
import torch
import torchvision.transforms as transforms
from PIL import Image
from io import BytesIO
import boto3
import os
from model import LogisticRegressionModel

# Configuration MinIO, a mettre dans le fichier .env
MINIO_ENDPOINT = "localhost:9000"  # Sans http:// ici pour boto3
MINIO_USER = os.getenv("MINIO_USER", "minio")
MINIO_PASS = os.getenv("MINIO_PASS", "miniopassword")
BUCKET_NAME = "bucket.romain"  
OBJECT_KEY = "model/model_2025-05-11_17-09-11_acc_75.00.pth"  

app = FastAPI(title="Image Classification API")
app = FastAPI(title="Image Classification API")

# Chargement du modÃ¨le une seule fois au dÃ©marrage
@app.on_event("startup")
def load_model():
    global model
    print("Connexion Ã  MinIO et chargement du modÃ¨le...")
           
    s3 = boto3.client(
        's3',
        endpoint_url=f"http://{MINIO_ENDPOINT}",
        aws_access_key_id=MINIO_USER,
        aws_secret_access_key=MINIO_PASS,
        region_name="us-east-1"
    )

    try:
        # Lister les objets du dossier "model/"
        response = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix="model/")
        all_keys = [obj['Key'] for obj in response.get("Contents", []) if obj['Key'].endswith(".pth")]

        if not all_keys:
            raise RuntimeError("Aucun fichier .pth trouvÃ© dans le bucket.")

        # Prendre le premier fichier .pth trouvÃ© (un peu lent, mlflow ne selectionne pas le meilleur modÃ¨le)
        selected_key = all_keys[0]
        print(f"ModÃ¨le trouvÃ© : {selected_key}")

        # TÃ©lÃ©charger ce modÃ¨le
        response = s3.get_object(Bucket=BUCKET_NAME, Key=selected_key)
        buffer = BytesIO(response['Body'].read())

        # Charger dans le modÃ¨le
        model = LogisticRegressionModel()
        model.load_state_dict(torch.load(buffer, map_location=torch.device("cpu")))
        model.eval()

        print("ModÃ¨le chargÃ© avec succÃ¨s depuis MinIO.")

    except Exception as e:
        print(f"Erreur lors du chargement du modÃ¨le : {e}")
        raise RuntimeError("Ã‰chec du tÃ©lÃ©chargement du modÃ¨le depuis MinIO.")

    # try:
    #     response = s3.get_object(Bucket=BUCKET_NAME, Key=OBJECT_KEY)
    #     model_data = response['Body'].read()
    #     buffer = BytesIO(model_data)

    #     model = LogisticRegressionModel()
    #     model.load_state_dict(torch.load(buffer, map_location=torch.device("cpu")))
    #     model.eval()

    #     print("ModÃ¨le chargÃ© depuis MinIO.")
    # except Exception as e:
    #     print(f"Erreur lors du chargement du modÃ¨le : {e}")
    #     raise RuntimeError("Ã‰chec du tÃ©lÃ©chargement du modÃ¨le depuis MinIO.")

# PrÃ©traitement de l'image
def preprocess_image(image_data: bytes):
    image = Image.open(BytesIO(image_data)).convert("RGB")
    transform = transforms.Compose([
        transforms.Resize((128, 128)),  # correspond Ã  ce que le modÃ¨le attend
        transforms.ToTensor(),
    ])
    return transform(image).unsqueeze(0)

# PrÃ©diction
def predict(image_tensor):
    with torch.no_grad():
        output = model(image_tensor)
        prob = output.item()
        return "dandelion" if prob >= 0.5 else "grass"

# Endpoint POST
@app.post("/predict")
async def predict_image(file: UploadFile = File(...)):
    if not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="Le fichier doit Ãªtre une image.")

    image_bytes = await file.read()
    print(f"ðŸ§ª Fichier reÃ§u : {file.filename}, {len(image_bytes)} octets")

    try:
        image_tensor = preprocess_image(image_bytes)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Erreur de lecture de l'image : {e}")

    prediction = predict(image_tensor)
    return JSONResponse(content={"prediction": prediction})


# Test de l'API
# curl -X POST "http://localhost:8000/predict" \
#   -H "accept: application/json" \
#   -H "Content-Type: multipart/form-data" \
#   -F "file=@photo.jpg"

# Requirements pour l'API
# fastapi
# uvicorn
# torch
# torchvision
# boto3
# pillow
# python-multipart


# Pour lancer l'API :
# uvicorn main:app --reload --port 8000